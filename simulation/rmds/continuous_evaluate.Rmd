---
title: "Evaluation for continuous structure discovery"
author: "Siyuan Ma"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
html_document:
df_print: paged
---
# Overview
Evaluation for continuous structure discovery

```{r setup, echo = FALSE}                                           
knitr::opts_knit$set(root.dir = normalizePath("../"))
# setwd("simulation/")
```
```{r setup2, message=FALSE, warning=FALSE, echo = FALSE}
rm(list = ls())
for(i.function in list.files("functions/", full.names = TRUE)) {
  source(i.function)
}
setup()
dir_output <- "results/continuous/"
dir.create(dir_output, recursive = TRUE, showWarnings = TRUE)
```

```{r load data}
# parallel computing
ncores <- 20
load(paste0(dir_output, "tb_sim.RData"))
```

```{r evaluate continuous score before correction}
N <- nrow(tb_sim)
registerDoParallel(ncores)
cutoff <- seq(0.5, 0.1, by = -0.1)
results <- foreach(i = 1:N) %dopar% {
  cat(i, "\n", file = paste0(dir_output, "evaluate_before_progress.txt"), append = TRUE)
  mat_otu <- read.table(paste0(dir_output,
                               "sparseDOSSA_sets/",
                               i, ".tsv"),
                        header = TRUE,
                        sep = "\t") %>% 
    as.matrix
  i_simSetup <- tb_sim[i, ]
  df_metadata <- i_simSetup$df_metadata[[1]]
  
  phylo <- phyloseq::phyloseq(
    phyloseq::otu_table(mat_otu, taxa_are_rows = TRUE),
    sample_data(df_metadata)) %>%
    transform_sample_counts(MMUPHin:::tss) %>%
    prune_taxaSamples()
  D <- distance(phylo, method = "bray")
  R2_batch <- vegan::adonis(D ~ batch,
                            data = sample_data2(phylo),
                            permutations = 2)$aov.tab["batch", "R2"]
  R2_score <- vegan::adonis(D ~ score,
                            data = sample_data2(phylo),
                            permutations = 2)$aov.tab["score", "R2"]
  
  for(cor.cutoff in cutoff) {
    fit.continuous <- MMUPHin::continuous.discover(feature.count = mat_otu,
                                                   batch = "batch",
                                                   data = df_metadata,
                                                   normalization = "TSS",
                                                   transform = "AST",
                                                   cor.cutoff = cor.cutoff,
                                                   diagnostics = FALSE,
                                                   network = FALSE,
                                                   verbose = FALSE)
    if(is.null(fit.continuous)) next
    if(length(fit.continuous$membership[[1]]) >= i_simSetup$nBatch) break
  }
  if(!is.null(fit.continuous)) {
    correlation <- mat_otu %>% 
      apply(2, MMUPHin:::tss) %>% sqrt() %>% asin %>% 
      t() %>% `%*%`(fit.continuous$consensus.loading[, 1]) %>% 
      cor(i_simSetup$df_metadata[[1]]$score, method = "spearman")
    return(list(R2 = c("batch" = R2_batch,
                       "score" = R2_score),
                fit.continuous = list(cor.cutoff = cor.cutoff,
                                      fit.continuous = fit.continuous,
                                      correlation = correlation[1, 1]))
    )
  }
  return(list(R2 = c("batch" = R2_batch,
                     "score" = R2_score),
              fit.continuous = NULL))
}
stopImplicitCluster()
save(results, file = paste0(dir_output, "evaluate_before.RData"))
```

```{r batch correction and continuous discovery}
registerDoParallel(ncores)
results_correct <- foreach(i = 1:N) %dopar% {
  cat(i, "\n", file = paste0(dir_output, "evaluate_after_progress.txt"), append = TRUE)
  mat_otu <- read.table(paste0(dir_output,
                               "sparseDOSSA_sets/",
                               i, ".tsv"),
                        header = TRUE,
                        sep = "\t") %>% 
    as.matrix
  i_simSetup <- tb_sim[i, ]
  df_metadata <- i_simSetup$df_metadata[[1]]
  
  mat_otu <- mat_otu %>% 
    MMUPHin::adjust.batch(batch = "batch", 
                          data = df_metadata,
                          diagnostics = FALSE, 
                          verbose = FALSE)
  
  phylo <- phyloseq::phyloseq(
    phyloseq::otu_table(mat_otu, taxa_are_rows = TRUE),
    sample_data(df_metadata)) %>%
    transform_sample_counts(MMUPHin:::tss) %>%
    prune_taxaSamples()
  D <- distance(phylo, method = "bray")
  R2_batch <- vegan::adonis(D ~ batch,
                            data = sample_data2(phylo),
                            permutations = 2)$aov.tab["batch", "R2"]
  R2_score <- vegan::adonis(D ~ score,
                            data = sample_data2(phylo),
                            permutations = 2)$aov.tab["score", "R2"]
  
  for(cor.cutoff in cutoff) {
    fit.continuous <- MMUPHin::continuous.discover(feature.count = mat_otu,
                                                   batch = "batch",
                                                   data = df_metadata,
                                                   normalization = "TSS",
                                                   transform = "AST",
                                                   cor.cutoff = cor.cutoff,
                                                   diagnostics = FALSE,
                                                   network = FALSE,
                                                   verbose = FALSE)
    if(is.null(fit.continuous)) next
    if(length(fit.continuous$membership[[1]]) >= i_simSetup$nBatch) break
  }
  if(!is.null(fit.continuous)) {
    correlation <- mat_otu %>% 
      apply(2, MMUPHin:::tss) %>% sqrt() %>% asin %>% 
      t() %>% `%*%`(fit.continuous$consensus.loading[, 1]) %>% 
      cor(i_simSetup$df_metadata[[1]]$score, method = "spearman")
    return(list(R2 = c("batch" = R2_batch,
                       "score" = R2_score),
                fit.continuous = list(cor.cutoff = cor.cutoff,
                                      fit.continuous = fit.continuous,
                                      correlation = correlation[1, 1]))
    )
  }
  return(list(R2 = c("batch" = R2_batch,
                     "score" = R2_score),
              fit.continuous = NULL))
}
stopImplicitCluster()
save(results_correct, file = paste0(dir_output, "evaluate_after.RData"))
```

